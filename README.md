# 音乐生成的算法研究  
本项目南京邮电大学大学生创新创业训练计划项目  
测试使用Transformer架构的可行性的方案

# 目标
我们的目标是训练一个可以生成具有流畅自然的听感的和弦进行的模型。它可以直接生成和弦进行，也可以在用户写好旋律以后为他的旋律来生成对应的和弦进行。  
这个模型可以被运用于给音乐制作人提供灵感，或者简化编曲的过程，也可以被用做给普通人提供一个把自己的歌曲变得更加精美的巧妙黑盒。  
试想你可曾有过这样的经历——你某一天突发灵感创作出了一段旋律，可由于你没有学习过作曲，你只能单调地横着这一段旋律，却没有办法把它写成完整的乐曲。今天，有了我们的模型，你就可以把你的灵感快速转变成一首有模有样的曲子。就算没有作曲知识，你也可以创作出属于你自己的曲子！

# 思路
## Attention is all you need
自从《Attention is All You Need》发布以来，它被运用于各行各业，其中颇为出圈的就是ChatGPT。似乎，这种注意力机制格外适合自然语言处理（NLP）任务。  
我们生成和弦的思路其实和NLP任务是一脉相承的。为什么？语言是一个一个词讲出来的，讲完一句话，它就有一个完整的含义。注意力机制恰好能够阐明语言前后的关联。那音乐呢？我们常说**音乐是一种世界性的语言**，你可能会认为这是一种比喻或类比……但它真的仅仅是比喻吗？音乐难道不本来就是一种“语言”吗？  
对于我们人类而言，平常的语言用来传达确切的信息，而音乐则更像是一种抽象的情绪表现，它们有着很大的差别，但是如果我们脱离开人的感官，假设我们就是一堆神经网络，仅仅从数据层面上看，音乐其实和语言没什么区别。甚至，音乐比像汉语、英语这样的语言来得更简单，也更自由。  

### token划分
在自然语言处理中，为了让我们的模型“认识”我们的文字，我们通常使用Tokenizer来处理文字。例如，OpenAI使用的是tiktoken。同样地，为了让模型“认识”乐谱，我们也需要通过某种方式把乐谱转化为一个个的Token。

### 解码器自注意力机制

## 首调模式
为了便于模型提取特征，减少干扰和参数量，我们决定所有和弦使用调式内的级数表示法，而非绝对表示。
## 数据集
由于我们的目标是生成一个偏向流行歌曲的和弦进行，我们的数据集应当能够较好地反应歌曲的和弦进行。起初我试图使用业界流行的maestro、adl-piano-midi、BACH DOODLE、MusicScore等数据集，然而，我发现这些  
事实上，最近，Transformer也有被运用于音乐生成领域，例如MusicTransformer项目，这是一个使用了maestro MIDI数据集训练而成的Transformer模型，生成的结果好像还像那么回事。只是MIDI看上去是一团乱麻。作为音乐制作人，我观察了他们所做的工作，发现他们使用的数据集内的很多歌曲的MIDI要不就是古典钢琴曲，那种旋律和和弦不是很明确区分的，本来作为人都不好寻找它的规律，又怎么去训练出一个辅助音乐人的AI呢？而另一个游戏音乐的MIDI集，其中又有很多写法奇奇怪怪的MIDI，这种技法用来流行音乐是不现实的，也是一种干扰性质的数据。  
好在，在查找了各种音乐类的数据集之后，我们发现有一个宝藏网站竟然收录了现成的两万多首流行歌曲的乐谱！不仅如此，它甚至还是每首歌严格分为旋律和和弦轨的。我勒个去，这不就是我想要的理想数据集吗？！于是，我们使用HookTheory数据集作为我们的训练用数据集，开始了我们的模型设计。
恰好HookTheory的数据集内的歌曲数据本就是首调表示法的。

# 乐理上的理论支撑 - 色彩和声

# 参考&引用
