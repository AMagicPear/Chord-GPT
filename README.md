# 音乐生成的算法研究  
本项目南京邮电大学大学生创新创业训练计划项目  
测试使用Transformer架构的可行性的方案

# 目标
我们的目标是训练一个可以生成具有流畅自然的听感的和弦进行的模型。它可以直接生成和弦进行，也可以在用户写好旋律以后为他的旋律来生成对应的和弦进行。  
这个模型可以被运用于给音乐制作人提供灵感，或者简化编曲的过程，也可以被用做给普通人提供一个把自己的歌曲变得更加精美的巧妙黑盒。  
试想你可曾有过这样的经历——你某一天突发灵感

# 思路
## Attention is all you need
自从《Attention is All You Need》发布以来，它被运用于各行各业，其中颇为出圈的就是ChatGPT。似乎，这种注意力机制格外适合自然语言处理（NLP）任务。最近，Transformer也有被运用于音乐生成领域，例如MusicTransformer项目，这是一个使用了maestro MIDI数据集训练而成的Transformer模型，生成的结果

### Decoder自注意力机制
- Decoder（即和弦生成器）采用自注意力机制。  
## 首调模式
为了便于模型提取特征，减少干扰和参数量，我们决定所有和弦使用调式内的级数表示法，而非绝对表示。
## 数据集
由于我们的目标是生成一个偏向流行歌曲的和弦进行，我们的数据集应当能够较好地反应歌曲的和弦进行。起初我试图使用业界流行的maestro、adl-piano-midi、BACH DOODLE、MusicScore等数据集，然而，我发现这些
恰好HookTheory的数据集内的歌曲数据本就是首调表示法的。